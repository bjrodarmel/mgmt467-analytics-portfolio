{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bjrodarmel/mgmt467-analytics-portfolio/blob/main/Unit2_Lab2_PartAFinsihed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40d6f791",
      "metadata": {
        "id": "40d6f791"
      },
      "source": [
        "\n",
        "# ü§ñ MGMT 467 - Unit 2 Lab 2: Prompt Studio for AI-Assisted SQL + ML\n",
        "\n",
        "**Date:** 2025-10-16  \n",
        "**Objective:** Build and refine a complete ML pipeline for churn prediction using BigQuery ‚Äî but with **Gemini-style prompts** guiding SQL generation.\n",
        "\n",
        "You'll learn to:\n",
        "- Frame SQL goals as clear prompts\n",
        "- Generate, test, and debug queries with an AI assistant\n",
        "- Reflect on each modeling step and your prompt design\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d46ebf07",
      "metadata": {
        "id": "d46ebf07"
      },
      "source": [
        "\n",
        "## Task 0: Connect to BigQuery\n",
        "\n",
        "**üéØ Goal:** Verify BigQuery access from Colab.  \n",
        "**üìå Requirements:** Use `%%bigquery`, get current date and user session.\n",
        "\n",
        "---\n",
        "\n",
        "### üß† Prompt Template  \n",
        "> Write a SQL query that returns CURRENT_DATE() and SESSION_USER(). I will run it with %%bigquery in Colab.\n",
        "\n",
        "---\n",
        "\n",
        "### üë©‚Äçüè´ Example Prompt  \n",
        "> Write a SQL query using BigQuery syntax that returns today‚Äôs date and the current session user.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ Expected SQL Output\n",
        "```sql\n",
        "SELECT CURRENT_DATE() AS today, SESSION_USER() AS user;\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### üîç Checkpoint  \n",
        "Query should return a single row with today's date and your user.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Using BigQuery, test connection by writing a SQL query to get current date and user session.\n",
        "\n",
        "from google.cloud import bigquery\n",
        "\n",
        "# Construct a BigQuery client object.\n",
        "client = bigquery.Client()\n",
        "\n",
        "query = \"\"\"\n",
        "SELECT CURRENT_DATE() AS today, SESSION_USER() AS user;\n",
        "\"\"\"\n",
        "\n",
        "query_job = client.query(query)  # Make an API request.\n",
        "results = query_job.result()  # Wait for the job to complete.\n",
        "\n",
        "for row in results:\n",
        "  print(f\"Today: {row.today}, User: {row.user}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkaXI2s-jZ0Q",
        "outputId": "3f582d12-3faa-49b2-ba81-0b763415aa93"
      },
      "id": "SkaXI2s-jZ0Q",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Today: 2025-10-26, User: bjrodarmel@gmail.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4804b5b0",
      "metadata": {
        "id": "4804b5b0"
      },
      "source": [
        "\n",
        "## Task 1: Prepare ML Table\n",
        "\n",
        "**üéØ Goal:** Create a clean features table for modeling churn.  \n",
        "**üìå Requirements:** Use cleaned_features as source, select relevant columns, filter rows with churn_label IS NOT NULL.\n",
        "\n",
        "---\n",
        "\n",
        "### üß† Prompt Template  \n",
        "> Write a query that creates a new table with columns: [region, plan_tier, age_band, ...] and churn_label from [source_table]. Filter to rows where churn_label IS NOT NULL.\n",
        "\n",
        "---\n",
        "\n",
        "### üë©‚Äçüè´ Example Prompt  \n",
        "> Create a BigQuery table named churn_features from cleaned_features with selected features and where churn_label IS NOT NULL.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ Expected SQL Output\n",
        "```sql\n",
        "CREATE OR REPLACE TABLE `your_dataset.churn_features` AS\n",
        "SELECT region, plan_tier, age_band, avg_rating, total_minutes, churn_label\n",
        "FROM `your_dataset.cleaned_features`\n",
        "WHERE churn_label IS NOT NULL;\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### üîç Checkpoint  \n",
        "Table should appear in BigQuery and contain non-null labels.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "# Construct a BigQuery client object.\n",
        "client = bigquery.Client()\n",
        "\n",
        "# NOTE: Ensure the dataset `Netflix` exists within your `mgmt-467` project.\n",
        "# You can create it manually in the BigQuery UI if it doesn't.\n",
        "query = \"\"\"\n",
        "CREATE OR REPLACE TABLE `mgmt-467.netflix.churn_features` AS\n",
        "SELECT\n",
        "    region,\n",
        "    plan_tier,\n",
        "    age_band,\n",
        "    avg_rating,\n",
        "    total_minutes,\n",
        "    churn_label\n",
        "FROM\n",
        "    `mgmt-467.netflix.cleaned_features`\n",
        "WHERE\n",
        "    churn_label IS NOT NULL;\n",
        "\"\"\"\n",
        "\n",
        "query_job = client.query(query)  # Make an API request.\n",
        "print(f\"Job {query_job.job_id} started.\")\n",
        "query_job.result()  # Wait for the job to complete.\n",
        "print(\"Table `mgmt-467.Netflix.churn_features` created successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "IifKsdiqlFnw",
        "outputId": "8f5de4a9-4fb7-4a4c-9607-2041c3fa00ad"
      },
      "id": "IifKsdiqlFnw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Job 1c251122-c5ac-4471-8227-5f162ed47a4e started.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NotFound",
          "evalue": "404 Not found: Table mgmt-467:netflix.cleaned_features was not found in location US; reason: notFound, message: Not found: Table mgmt-467:netflix.cleaned_features was not found in location US\n\nLocation: US\nJob ID: 1c251122-c5ac-4471-8227-5f162ed47a4e\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFound\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2834649889.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mquery_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Make an API request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Job {query_job.job_id} started.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mquery_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Wait for the job to complete.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Table `mgmt-467.Netflix.churn_features` created successfully.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/cloud/bigquery/job/query.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, page_size, max_results, retry, timeout, start_index, job_retry)\u001b[0m\n\u001b[1;32m   1679\u001b[0m                 \u001b[0;31m# Since is_job_done() calls jobs.getQueryResults, which is a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1680\u001b[0m                 \u001b[0;31m# long-running API, don't delay the next request at all.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1681\u001b[0;31m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_job_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1682\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1683\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             )\n\u001b[0;32m--> 294\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    295\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;31m# defer to shared logic for handling errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             next_sleep = _retry_error_helper(\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0mdeadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_base.py\u001b[0m in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0moriginal_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         )\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfinal_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msource_exc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mon_error_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mon_error_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ASYNC_RETRY_WARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/cloud/bigquery/job/query.py\u001b[0m in \u001b[0;36mis_job_done\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1628\u001b[0m                         \u001b[0;31m# `job_retry` predicate.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1629\u001b[0m                         \u001b[0mrestart_query_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1630\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mjob_failed_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1631\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m                         \u001b[0;31m# Make sure that the _query_results are cached so we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFound\u001b[0m: 404 Not found: Table mgmt-467:netflix.cleaned_features was not found in location US; reason: notFound, message: Not found: Table mgmt-467:netflix.cleaned_features was not found in location US\n\nLocation: US\nJob ID: 1c251122-c5ac-4471-8227-5f162ed47a4e\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d5627fe"
      },
      "source": [
        "# Task\n",
        "Define the schema for the `mgmt-467.netflix.cleaned_features` table, including how to derive `region`, `plan_tier`, `age_band`, `avg_rating`, `total_minutes`, and `churn_label` from the `movies`, `recommendation_logs`, `reviews`, `search_log`, `users`, and `watch_history` tables. Then, provide the SQL query to create this `cleaned_features` table."
      ],
      "id": "3d5627fe"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b29df84a"
      },
      "source": [
        "## Define cleaned_features Schema and Joins\n",
        "\n",
        "### Subtask:\n",
        "Explicitly define how each target feature (region, plan_tier, age_band, avg_rating, total_minutes, churn_label) will be derived from the source tables (movies, recommendation_logs, reviews, search_log, users, watch_history).\n"
      ],
      "id": "b29df84a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "890220a0"
      },
      "source": [
        "```markdown\n",
        "## Define cleaned_features Schema and Joins\n",
        "\n",
        "### Feature Derivation Details\n",
        "\n",
        "For the `cleaned_features` table, the target features will be derived from the following hypothetical source tables and columns:\n",
        "\n",
        "*   **users**: `user_id`, `region`, `plan_tier`, `age`, `churn_label` (or `subscription_status`)\n",
        "*   **reviews**: `user_id`, `rating`\n",
        "*   **watch_history**: `user_id`, `duration_minutes`\n",
        "\n",
        "Here's how each target feature is derived:\n",
        "\n",
        "1.  **`region`**\n",
        "    *   **Source Column(s):** `users.region`\n",
        "    *   **Join Conditions:** No direct join needed if `users` is the base table for selection. If not, join with `users` on `user_id`.\n",
        "    *   **Transformation Logic:** Direct selection.\n",
        "\n",
        "2.  **`plan_tier`**\n",
        "    *   **Source Column(s):** `users.plan_tier`\n",
        "    *   **Join Conditions:** No direct join needed if `users` is the base table for selection. If not, join with `users` on `user_id`.\n",
        "    *   **Transformation Logic:** Direct selection.\n",
        "\n",
        "3.  **`age_band`**\n",
        "    *   **Source Column(s):** `users.age`\n",
        "    *   **Join Conditions:** No direct join needed if `users` is the base table for selection. If not, join with `users` on `user_id`.\n",
        "    *   **Transformation Logic:** Categorization of `users.age` into bands. For example:\n",
        "        ```sql\n",
        "        CASE\n",
        "            WHEN users.age < 18 THEN '0-17'\n",
        "            WHEN users.age BETWEEN 18 AND 24 THEN '18-24'\n",
        "            WHEN users.age BETWEEN 25 AND 34 THEN '25-34'\n",
        "            WHEN users.age BETWEEN 35 AND 44 THEN '35-44'\n",
        "            WHEN users.age BETWEEN 45 AND 54 THEN '45-54'\n",
        "            WHEN users.age BETWEEN 55 AND 64 THEN '55-64'\n",
        "            ELSE '65+'\n",
        "        END AS age_band\n",
        "        ```\n",
        "\n",
        "4.  **`avg_rating`**\n",
        "    *   **Source Column(s):** `reviews.rating`\n",
        "    *   **Join Conditions:** `users` `LEFT JOIN` `reviews` `ON users.user_id = reviews.user_id`\n",
        "    *   **Transformation Logic:** Calculate the average `rating` given by each user. Users who have not given any reviews will have a `NULL` for `avg_rating` or it could be imputed to 0.\n",
        "        ```sql\n",
        "        AVG(reviews.rating) OVER (PARTITION BY users.user_id) AS avg_rating\n",
        "        ```\n",
        "\n",
        "5.  **`total_minutes`**\n",
        "    *   **Source Column(s):** `watch_history.duration_minutes`\n",
        "    *   **Join Conditions:** `users` `LEFT JOIN` `watch_history` `ON users.user_id = watch_history.user_id`\n",
        "    *   **Transformation Logic:** Sum the `duration_minutes` for all watched items by each user. Users with no watch history will have a `NULL` for `total_minutes` or it could be imputed to 0.\n",
        "        ```sql\n",
        "        SUM(watch_history.duration_minutes) OVER (PARTITION BY users.user_id) AS total_minutes\n",
        "        ```\n",
        "\n",
        "6.  **`churn_label`**\n",
        "    *   **Source Column(s):** `users.churn_label` (assuming a direct column, or `users.subscription_status` for derivation)\n",
        "    *   **Join Conditions:** No direct join needed if `users` is the base table for selection. If not, join with `users` on `user_id`.\n",
        "    *   **Transformation Logic:** Direct selection of `users.churn_label`. (If `churn_label` is to be derived from `subscription_status`, it would be `CASE WHEN users.subscription_status = 'churned' THEN 1 ELSE 0 END AS churn_label`).\n",
        "\n",
        "**Overall Join Strategy:**\n",
        "The `users` table will serve as the central table. `reviews` and `watch_history` tables will be joined to the `users` table using `user_id` to aggregate user-specific metrics. A `LEFT JOIN` is preferred to retain all users, even those without reviews or watch history.\n",
        "\n",
        "```"
      ],
      "id": "890220a0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "380d2f47"
      },
      "source": [
        "## Create cleaned_features Table\n",
        "\n",
        "### Subtask:\n",
        "Generate and execute the SQL query to create the `mgmt-467.netflix.cleaned_features` table based on the defined schema and join logic.\n"
      ],
      "id": "380d2f47"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bb06733"
      },
      "source": [
        "**Reasoning**:\n",
        "The goal is to create the `mgmt-467.netflix.cleaned_features` table. This requires constructing a SQL query that joins the `users`, `reviews`, and `watch_history` tables, calculates `age_band`, `avg_rating`, and `total_minutes`, and then executing this query using the BigQuery client.\n",
        "\n"
      ],
      "id": "8bb06733"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "135a1e6c",
        "outputId": "7baa320d-59d4-4c9c-d08b-cd623a1eedec"
      },
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "# Construct a BigQuery client object.\n",
        "client = bigquery.Client()\n",
        "\n",
        "query_create_cleaned_features = \"\"\"\n",
        "CREATE OR REPLACE TABLE `mgmt-467.netflix.cleaned_features` AS\n",
        "WITH\n",
        "  avg_ratings_cte AS (\n",
        "    SELECT\n",
        "      user_id,\n",
        "      AVG(rating) AS avg_rating\n",
        "    FROM\n",
        "      `mgmt-467.netflix.reviews`\n",
        "    GROUP BY\n",
        "      user_id\n",
        "  ),\n",
        "  total_minutes_cte AS (\n",
        "    SELECT\n",
        "      user_id,\n",
        "      SUM(duration_minutes) AS total_minutes\n",
        "    FROM\n",
        "      `mgmt-467.netflix.watch_history`\n",
        "    GROUP BY\n",
        "      user_id\n",
        "  )\n",
        "SELECT\n",
        "  u.user_id,\n",
        "  u.region,\n",
        "  u.plan_tier,\n",
        "  CASE\n",
        "    WHEN u.age < 18 THEN '0-17'\n",
        "    WHEN u.age BETWEEN 18 AND 24 THEN '18-24'\n",
        "    WHEN u.age BETWEEN 25 AND 34 THEN '25-34'\n",
        "    WHEN u.age BETWEEN 35 AND 44 THEN '35-44'\n",
        "    WHEN u.age BETWEEN 45 AND 54 THEN '45-54'\n",
        "    WHEN u.age BETWEEN 55 AND 64 THEN '55-64'\n",
        "    ELSE '65+'\n",
        "  END AS age_band,\n",
        "  COALESCE(ar.avg_rating, 0) AS avg_rating, -- Default to 0 if no reviews\n",
        "  COALESCE(tm.total_minutes, 0) AS total_minutes, -- Default to 0 if no watch history\n",
        "  u.churn_label\n",
        "FROM\n",
        "  `mgmt-467.netflix.users` AS u\n",
        "LEFT JOIN\n",
        "  avg_ratings_cte AS ar\n",
        "ON\n",
        "  u.user_id = ar.user_id\n",
        "LEFT JOIN\n",
        "  total_minutes_cte AS tm\n",
        "ON\n",
        "  u.user_id = tm.user_id;\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    query_job = client.query(query_create_cleaned_features)  # Make an API request.\n",
        "    print(f\"Job {query_job.job_id} started to create cleaned_features table.\")\n",
        "    query_job.result()  # Wait for the job to complete.\n",
        "    print(\"Table `mgmt-467.netflix.cleaned_features` created successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error creating table `mgmt-467.netflix.cleaned_features`: {e}\")"
      ],
      "id": "135a1e6c",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Job c39ea640-256a-4069-8d0a-9873bc418afb started to create cleaned_features table.\n",
            "Error creating table `mgmt-467.netflix.cleaned_features`: 400 Unrecognized name: duration_minutes at [16:11]; reason: invalidQuery, location: query, message: Unrecognized name: duration_minutes at [16:11]\n",
            "\n",
            "Location: US\n",
            "Job ID: c39ea640-256a-4069-8d0a-9873bc418afb\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "292cdcef"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code execution failed because the `duration_minutes` column was not found in the `watch_history` table, indicating an incorrect column name in the SQL query. I will update the query to use a more plausible column name, `watch_duration`, for the total minutes calculation. If this still fails, the actual schema for `watch_history` will need to be verified.\n",
        "\n"
      ],
      "id": "292cdcef"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5238bd81",
        "outputId": "25e01164-2033-4158-9e12-da5f5455d91d"
      },
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "# Construct a BigQuery client object.\n",
        "client = bigquery.Client()\n",
        "\n",
        "query_create_cleaned_features = \"\"\"\n",
        "CREATE OR REPLACE TABLE `mgmt-467.netflix.cleaned_features` AS\n",
        "WITH\n",
        "  avg_ratings_cte AS (\n",
        "    SELECT\n",
        "      user_id,\n",
        "      AVG(rating) AS avg_rating\n",
        "    FROM\n",
        "      `mgmt-467.netflix.reviews`\n",
        "    GROUP BY\n",
        "      user_id\n",
        "  ),\n",
        "  total_minutes_cte AS (\n",
        "    SELECT\n",
        "      user_id,\n",
        "      SUM(watch_duration) AS total_minutes -- Changed from duration_minutes\n",
        "    FROM\n",
        "      `mgmt-467.netflix.watch_history`\n",
        "    GROUP BY\n",
        "      user_id\n",
        "  )\n",
        "SELECT\n",
        "  u.user_id,\n",
        "  u.region,\n",
        "  u.plan_tier,\n",
        "  CASE\n",
        "    WHEN u.age < 18 THEN '0-17'\n",
        "    WHEN u.age BETWEEN 18 AND 24 THEN '18-24'\n",
        "    WHEN u.age BETWEEN 25 AND 34 THEN '25-34'\n",
        "    WHEN u.age BETWEEN 35 AND 44 THEN '35-44'\n",
        "    WHEN u.age BETWEEN 45 AND 54 THEN '45-54'\n",
        "    WHEN u.age BETWEEN 55 AND 64 THEN '55-64'\n",
        "    ELSE '65+'\n",
        "  END AS age_band,\n",
        "  COALESCE(ar.avg_rating, 0) AS avg_rating, -- Default to 0 if no reviews\n",
        "  COALESCE(tm.total_minutes, 0) AS total_minutes, -- Default to 0 if no watch history\n",
        "  u.churn_label\n",
        "FROM\n",
        "  `mgmt-467.netflix.users` AS u\n",
        "LEFT JOIN\n",
        "  avg_ratings_cte AS ar\n",
        "ON\n",
        "  u.user_id = ar.user_id\n",
        "LEFT JOIN\n",
        "  total_minutes_cte AS tm\n",
        "ON\n",
        "  u.user_id = tm.user_id;\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    query_job = client.query(query_create_cleaned_features)  # Make an API request.\n",
        "    print(f\"Job {query_job.job_id} started to create cleaned_features table.\")\n",
        "    query_job.result()  # Wait for the job to complete.\n",
        "    print(\"Table `mgmt-467.netflix.cleaned_features` created successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error creating table `mgmt-467.netflix.cleaned_features`: {e}\")"
      ],
      "id": "5238bd81",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Job 5f926127-1c67-4338-a5a5-f6e3d83de6a8 started to create cleaned_features table.\n",
            "Error creating table `mgmt-467.netflix.cleaned_features`: 400 Unrecognized name: watch_duration at [16:11]; reason: invalidQuery, location: query, message: Unrecognized name: watch_duration at [16:11]\n",
            "\n",
            "Location: US\n",
            "Job ID: 5f926127-1c67-4338-a5a5-f6e3d83de6a8\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de4b4282"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempts to create `cleaned_features` failed due to unrecognized column names in the `watch_history` table. To resolve this, I need to inspect the schema of the `mgmt-467.netflix.watch_history` table to find the correct column name for watch duration. I will use `INFORMATION_SCHEMA.COLUMNS` to get column details.\n",
        "\n"
      ],
      "id": "de4b4282"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e608745",
        "outputId": "d3a522b2-f9f6-4465-bf14-8beed6d6fa37"
      },
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "client = bigquery.Client()\n",
        "\n",
        "query_schema = \"\"\"\n",
        "SELECT\n",
        "    column_name, data_type\n",
        "FROM\n",
        "    `mgmt-467.netflix.INFORMATION_SCHEMA.COLUMNS`\n",
        "WHERE\n",
        "    table_name = 'watch_history';\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    query_job = client.query(query_schema)\n",
        "    print(f\"Job {query_job.job_id} started to retrieve schema for watch_history.\")\n",
        "    results = query_job.result() # Wait for the job to complete.\n",
        "\n",
        "    print(\"Schema for `mgmt-467.netflix.watch_history`:\")\n",
        "    for row in results:\n",
        "        print(f\"  Column: {row.column_name}, Type: {row.data_type}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error retrieving schema for watch_history: {e}\")"
      ],
      "id": "3e608745",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Job 20bf0440-368e-4682-9ea5-70f38b1f63c7 started to retrieve schema for watch_history.\n",
            "Schema for `mgmt-467.netflix.watch_history`:\n",
            "  Column: session_id, Type: STRING\n",
            "  Column: user_id, Type: STRING\n",
            "  Column: movie_id, Type: STRING\n",
            "  Column: watch_date, Type: DATE\n",
            "  Column: device_type, Type: STRING\n",
            "  Column: watch_duration_minutes, Type: FLOAT64\n",
            "  Column: progress_percentage, Type: FLOAT64\n",
            "  Column: action, Type: STRING\n",
            "  Column: quality, Type: STRING\n",
            "  Column: location_country, Type: STRING\n",
            "  Column: is_download, Type: BOOL\n",
            "  Column: user_rating, Type: INT64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4d2be89"
      },
      "source": [
        "**Reasoning**:\n",
        "The schema retrieval revealed that the correct column name for watch duration in the `watch_history` table is `watch_duration_minutes`. I will now update the SQL query to use this correct column name and re-attempt to create the `cleaned_features` table.\n",
        "\n"
      ],
      "id": "c4d2be89"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdd48895",
        "outputId": "8a9b6056-7c0f-481e-ee3c-d700d2655ec0"
      },
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "# Construct a BigQuery client object.\n",
        "client = bigquery.Client()\n",
        "\n",
        "query_create_cleaned_features = \"\"\"\n",
        "CREATE OR REPLACE TABLE `mgmt-467.netflix.cleaned_features` AS\n",
        "WITH\n",
        "  avg_ratings_cte AS (\n",
        "    SELECT\n",
        "      user_id,\n",
        "      AVG(rating) AS avg_rating\n",
        "    FROM\n",
        "      `mgmt-467.netflix.reviews`\n",
        "    GROUP BY\n",
        "      user_id\n",
        "  ),\n",
        "  total_minutes_cte AS (\n",
        "    SELECT\n",
        "      user_id,\n",
        "      SUM(watch_duration_minutes) AS total_minutes -- Corrected column name\n",
        "    FROM\n",
        "      `mgmt-467.netflix.watch_history`\n",
        "    GROUP BY\n",
        "      user_id\n",
        "  )\n",
        "SELECT\n",
        "  u.user_id,\n",
        "  u.region,\n",
        "  u.plan_tier,\n",
        "  CASE\n",
        "    WHEN u.age < 18 THEN '0-17'\n",
        "    WHEN u.age BETWEEN 18 AND 24 THEN '18-24'\n",
        "    WHEN u.age BETWEEN 25 AND 34 THEN '25-34'\n",
        "    WHEN u.age BETWEEN 35 AND 44 THEN '35-44'\n",
        "    WHEN u.age BETWEEN 45 AND 54 THEN '45-54'\n",
        "    WHEN u.age BETWEEN 55 AND 64 THEN '55-64'\n",
        "    ELSE '65+'\n",
        "  END AS age_band,\n",
        "  COALESCE(ar.avg_rating, 0) AS avg_rating, -- Default to 0 if no reviews\n",
        "  COALESCE(tm.total_minutes, 0) AS total_minutes, -- Default to 0 if no watch history\n",
        "  u.churn_label\n",
        "FROM\n",
        "  `mgmt-467.netflix.users` AS u\n",
        "LEFT JOIN\n",
        "  avg_ratings_cte AS ar\n",
        "ON\n",
        "  u.user_id = ar.user_id\n",
        "LEFT JOIN\n",
        "  total_minutes_cte AS tm\n",
        "ON\n",
        "  u.user_id = tm.user_id;\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    query_job = client.query(query_create_cleaned_features)  # Make an API request.\n",
        "    print(f\"Job {query_job.job_id} started to create cleaned_features table.\")\n",
        "    query_job.result()  # Wait for the job to complete.\n",
        "    print(\"Table `mgmt-467.netflix.cleaned_features` created successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error creating table `mgmt-467.netflix.cleaned_features`: {e}\")"
      ],
      "id": "bdd48895",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Job 02d6a53d-3fba-4aab-8ca7-51dce2fde1af started to create cleaned_features table.\n",
            "Error creating table `mgmt-467.netflix.cleaned_features`: 400 Name region not found inside u at [24:5]; reason: invalidQuery, location: query, message: Name region not found inside u at [24:5]\n",
            "\n",
            "Location: US\n",
            "Job ID: 02d6a53d-3fba-4aab-8ca7-51dce2fde1af\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de62567c"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempt to create `cleaned_features` failed because the column `region` was not found in the `users` table (`u`). To resolve this, I need to inspect the schema of the `mgmt-467.netflix.users` table to find the correct column names for all user-related fields (`region`, `plan_tier`, `age`, and `churn_label`). I will use `INFORMATION_SCHEMA.COLUMNS` to get column details.\n",
        "\n"
      ],
      "id": "de62567c"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d71f286",
        "outputId": "59c206dd-a947-4fe7-ed8d-af7847052013"
      },
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "client = bigquery.Client()\n",
        "\n",
        "query_schema = \"\"\"\n",
        "SELECT\n",
        "    column_name, data_type\n",
        "FROM\n",
        "    `mgmt-467.netflix.INFORMATION_SCHEMA.COLUMNS`\n",
        "WHERE\n",
        "    table_name = 'users';\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    query_job = client.query(query_schema)\n",
        "    print(f\"Job {query_job.job_id} started to retrieve schema for users.\")\n",
        "    results = query_job.result() # Wait for the job to complete.\n",
        "\n",
        "    print(\"Schema for `mgmt-467.netflix.users`:\")\n",
        "    for row in results:\n",
        "        print(f\"  Column: {row.column_name}, Type: {row.data_type}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error retrieving schema for users: {e}\")"
      ],
      "id": "1d71f286",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Job 82f77627-f598-40fa-b7d7-9d88a8ec2a1f started to retrieve schema for users.\n",
            "Schema for `mgmt-467.netflix.users`:\n",
            "  Column: user_id, Type: STRING\n",
            "  Column: email, Type: STRING\n",
            "  Column: first_name, Type: STRING\n",
            "  Column: last_name, Type: STRING\n",
            "  Column: age, Type: FLOAT64\n",
            "  Column: gender, Type: STRING\n",
            "  Column: country, Type: STRING\n",
            "  Column: state_province, Type: STRING\n",
            "  Column: city, Type: STRING\n",
            "  Column: subscription_plan, Type: STRING\n",
            "  Column: subscription_start_date, Type: DATE\n",
            "  Column: is_active, Type: BOOL\n",
            "  Column: monthly_spend, Type: FLOAT64\n",
            "  Column: primary_device, Type: STRING\n",
            "  Column: household_size, Type: FLOAT64\n",
            "  Column: created_at, Type: TIMESTAMP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "403a54c6"
      },
      "source": [
        "**Reasoning**:\n",
        "The schema retrieval for the `users` table revealed that `region` should be `country`, `plan_tier` should be `subscription_plan`, `age` is correct, and `churn_label` can be derived from `is_active`. I will update the SQL query with these corrected column names and re-attempt to create the `cleaned_features` table.\n",
        "\n"
      ],
      "id": "403a54c6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35f002f2",
        "outputId": "9ef88a4f-de0f-4a29-94a6-8e5d6179c509"
      },
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "# Construct a BigQuery client object.\n",
        "client = bigquery.Client()\n",
        "\n",
        "query_create_cleaned_features = \"\"\"\n",
        "CREATE OR REPLACE TABLE `mgmt-467.netflix.cleaned_features` AS\n",
        "WITH\n",
        "  avg_ratings_cte AS (\n",
        "    SELECT\n",
        "      user_id,\n",
        "      AVG(rating) AS avg_rating\n",
        "    FROM\n",
        "      `mgmt-467.netflix.reviews`\n",
        "    GROUP BY\n",
        "      user_id\n",
        "  ),\n",
        "  total_minutes_cte AS (\n",
        "    SELECT\n",
        "      user_id,\n",
        "      SUM(watch_duration_minutes) AS total_minutes\n",
        "    FROM\n",
        "      `mgmt-467.netflix.watch_history`\n",
        "    GROUP BY\n",
        "      user_id\n",
        "  )\n",
        "SELECT\n",
        "  u.user_id,\n",
        "  u.country AS region, -- Corrected column name\n",
        "  u.subscription_plan AS plan_tier, -- Corrected column name\n",
        "  CASE\n",
        "    WHEN u.age < 18 THEN '0-17'\n",
        "    WHEN u.age BETWEEN 18 AND 24 THEN '18-24'\n",
        "    WHEN u.age BETWEEN 25 AND 34 THEN '25-34'\n",
        "    WHEN u.age BETWEEN 35 AND 44 THEN '35-44'\n",
        "    WHEN u.age BETWEEN 45 AND 54 THEN '45-54'\n",
        "    WHEN u.age BETWEEN 55 AND 64 THEN '55-64'\n",
        "    ELSE '65+'\n",
        "  END AS age_band,\n",
        "  COALESCE(ar.avg_rating, 0) AS avg_rating,\n",
        "  COALESCE(tm.total_minutes, 0) AS total_minutes,\n",
        "  CASE WHEN u.is_active = FALSE THEN 1 ELSE 0 END AS churn_label -- Derived from is_active\n",
        "FROM\n",
        "  `mgmt-467.netflix.users` AS u\n",
        "LEFT JOIN\n",
        "  avg_ratings_cte AS ar\n",
        "ON\n",
        "  u.user_id = ar.user_id\n",
        "LEFT JOIN\n",
        "  total_minutes_cte AS tm\n",
        "ON\n",
        "  u.user_id = tm.user_id;\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    query_job = client.query(query_create_cleaned_features)  # Make an API request.\n",
        "    print(f\"Job {query_job.job_id} started to create cleaned_features table.\")\n",
        "    query_job.result()  # Wait for the job to complete.\n",
        "    print(\"Table `mgmt-467.netflix.cleaned_features` created successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error creating table `mgmt-467.netflix.cleaned_features`: {e}\")"
      ],
      "id": "35f002f2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Job a673a298-3363-4479-9fbc-4dba9a6b6199 started to create cleaned_features table.\n",
            "Table `mgmt-467.netflix.cleaned_features` created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77752366"
      },
      "source": [
        "## Create Churn Features Table\n",
        "\n",
        "### Subtask:\n",
        "After `cleaned_features` is successfully created, generate and execute the SQL query to create the `mgmt-467.netflix.churn_features` table using `region, plan_tier, age_band, avg_rating, total_minutes, and churn_label` from `mgmt-467.netflix.cleaned_features`, filtering where `churn_label IS NOT NULL`.\n"
      ],
      "id": "77752366"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72182097"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous step successfully created the `cleaned_features` table. Now, I will generate and execute the SQL query to create the `churn_features` table based on the specified columns and filtering criteria from the `cleaned_features` table, as per the subtask instructions.\n",
        "\n"
      ],
      "id": "72182097"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce219a34",
        "outputId": "824744e3-2494-427d-f69f-7facda406a9d"
      },
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "# Construct a BigQuery client object.\n",
        "client = bigquery.Client()\n",
        "\n",
        "query_create_churn_features = \"\"\"\n",
        "CREATE OR REPLACE TABLE `mgmt-467.netflix.churn_features` AS\n",
        "SELECT\n",
        "    region,\n",
        "    plan_tier,\n",
        "    age_band,\n",
        "    avg_rating,\n",
        "    total_minutes,\n",
        "    churn_label\n",
        "FROM\n",
        "    `mgmt-467.netflix.cleaned_features`\n",
        "WHERE\n",
        "    churn_label IS NOT NULL;\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    query_job = client.query(query_create_churn_features)  # Make an API request.\n",
        "    print(f\"Job {query_job.job_id} started to create churn_features table.\")\n",
        "    query_job.result()  # Wait for the job to complete.\n",
        "    print(\"Table `mgmt-467.netflix.churn_features` created successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error creating table `mgmt-467.netflix.churn_features`: {e}\")"
      ],
      "id": "ce219a34",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Job 7aca3e03-4e3f-4f41-bfa1-4841079ce86d started to create churn_features table.\n",
            "Table `mgmt-467.netflix.churn_features` created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "446a71dc"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Confirm the successful creation of both `cleaned_features` and `churn_features` tables.\n"
      ],
      "id": "446a71dc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "697d8c81"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   **`cleaned_features` Table Schema Defined:** A comprehensive schema for the `cleaned_features` table was defined, outlining the derivation of each field:\n",
        "    *   `region` and `plan_tier` were derived from `users.country` and `users.subscription_plan`, respectively.\n",
        "    *   `age_band` was categorized from `users.age` into specific ranges (e.g., '0-17', '18-24', '65+').\n",
        "    *   `avg_rating` was calculated as the average `rating` per user from the `reviews` table.\n",
        "    *   `total_minutes` represented the sum of `watch_duration_minutes` per user from the `watch_history` table.\n",
        "    *   `churn_label` was derived from `users.is_active` (0 for active, 1 for inactive/churned).\n",
        "*   **Successful Creation of `cleaned_features`:** The `mgmt-467.netflix.cleaned_features` table was successfully created in BigQuery after iterative debugging. Initial attempts failed due to incorrect column names (`duration_minutes`, `watch_duration` in `watch_history`; `region`, `plan_tier`, `churn_label` in `users`), which were resolved by querying the `INFORMATION_SCHEMA.COLUMNS` for the respective tables.\n",
        "*   **Successful Creation of `churn_features`:** The `mgmt-467.netflix.churn_features` table was subsequently created from `cleaned_features`, including `region, plan_tier, age_band, avg_rating, total_minutes,` and `churn_label`, with a filter applied to include only records where `churn_label IS NOT NULL`.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The detailed feature engineering for `cleaned_features` provides a robust foundation for churn prediction models, encapsulating key user demographics, engagement, and sentiment.\n",
        "*   The `churn_features` table is now ready for use in machine learning model training, offering a pre-processed dataset specifically tailored for churn analysis.\n"
      ],
      "id": "697d8c81"
    },
    {
      "cell_type": "markdown",
      "id": "178327da",
      "metadata": {
        "id": "178327da"
      },
      "source": [
        "\n",
        "## Task 2: Train Logistic Regression Model\n",
        "\n",
        "**üéØ Goal:** Train a basic BQML logistic regression model.  \n",
        "**üìå Requirements:** Use churn_features table, predict churn_label from features.\n",
        "\n",
        "---\n",
        "\n",
        "### üß† Prompt Template  \n",
        "> Write a CREATE MODEL SQL for logistic regression using churn_label as label and [features] as inputs.\n",
        "\n",
        "---\n",
        "\n",
        "### üë©‚Äçüè´ Example Prompt  \n",
        "> Train a logistic regression model to predict churn_label using region, plan_tier, total_minutes, avg_rating.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ Expected SQL Output\n",
        "```sql\n",
        "CREATE OR REPLACE MODEL `your_dataset.churn_model`\n",
        "OPTIONS(model_type='logistic_reg') AS\n",
        "SELECT region, plan_tier, total_minutes, avg_rating, churn_label\n",
        "FROM `your_dataset.churn_features`;\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### üîç Checkpoint  \n",
        "Model appears in BigQuery under Models. Training completes.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "# Construct a BigQuery client object.\n",
        "client = bigquery.Client()\n",
        "\n",
        "query_create_model = \"\"\"\n",
        "CREATE OR REPLACE MODEL `mgmt-467.netflix.churn_model`\n",
        "OPTIONS(model_type='logistic_reg', input_label_cols=['churn_label'])\n",
        "AS\n",
        "SELECT\n",
        "    region,\n",
        "    plan_tier,\n",
        "    age_band,\n",
        "    avg_rating,\n",
        "    total_minutes,\n",
        "    churn_label\n",
        "FROM\n",
        "    `mgmt-467.netflix.churn_features`;\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    query_job = client.query(query_create_model)  # Make an API request.\n",
        "    print(f\"Job {query_job.job_id} started to create churn_model.\")\n",
        "    query_job.result()  # Wait for the job to complete.\n",
        "    print(\"Model `mgmt-467.netflix.churn_model` created successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error creating model `mgmt-467.netflix.churn_model`: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grtRNzeNpe27",
        "outputId": "3c8a39e9-0f4f-410a-d616-45550072519f"
      },
      "id": "grtRNzeNpe27",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Job 116144e7-7b0f-409d-9497-6ae0e57dd2d5 started to create churn_model.\n",
            "Model `mgmt-467.netflix.churn_model` created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e12488fb",
      "metadata": {
        "id": "e12488fb"
      },
      "source": [
        "\n",
        "## Task 3: Evaluate Model\n",
        "\n",
        "**üéØ Goal:** Evaluate the logistic regression model.  \n",
        "**üìå Requirements:** Use ML.EVALUATE.\n",
        "\n",
        "---\n",
        "\n",
        "### üß† Prompt Template  \n",
        "> Write a query to evaluate my logistic regression model using ML.EVALUATE.\n",
        "\n",
        "---\n",
        "\n",
        "### üë©‚Äçüè´ Example Prompt  \n",
        "> Evaluate the churn_model using ML.EVALUATE to get accuracy, precision, recall.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ Expected SQL Output\n",
        "```sql\n",
        "SELECT * FROM ML.EVALUATE(MODEL `your_dataset.churn_model`);\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### üîç Checkpoint  \n",
        "View performance metrics: accuracy, log_loss, precision, recall.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Use ML.EVALUATE in order to asses the model created in the previous step. Please use metrics like accuracy, precision, recall, and log loss.\n",
        "\n",
        "from google.cloud import bigquery\n",
        "\n",
        "# Construct a BigQuery client object.\n",
        "client = bigquery.Client()\n",
        "\n",
        "query_evaluate_model = \"\"\"\n",
        "SELECT\n",
        "    *\n",
        "FROM\n",
        "    ML.EVALUATE(MODEL `mgmt-467.netflix.churn_model`);\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    query_job = client.query(query_evaluate_model)  # Make an API request.\n",
        "    print(f\"Job {query_job.job_id} started to evaluate churn_model.\")\n",
        "    results = query_job.result()  # Wait for the job to complete.\n",
        "\n",
        "    print(\"Model Evaluation Results:\")\n",
        "    for row in results:\n",
        "        print(f\"  Accuracy: {row.accuracy}\")\n",
        "        print(f\"  Log Loss: {row.log_loss}\")\n",
        "        print(f\"  Precision: {row.precision}\")\n",
        "        print(f\"  Recall: {row.recall}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error evaluating model `mgmt-467.netflix.churn_model`: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XH_yGaQKqRmj",
        "outputId": "27413798-5e3e-485a-f736-1c44da1dba77"
      },
      "id": "XH_yGaQKqRmj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Job 5dc67173-4589-4551-bed0-7a8d24845bdd started to evaluate churn_model.\n",
            "Model Evaluation Results:\n",
            "  Accuracy: 0.8496166213208014\n",
            "  Log Loss: 0.42349457226866244\n",
            "  Precision: 0.0\n",
            "  Recall: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4dde2b93",
      "metadata": {
        "id": "4dde2b93"
      },
      "source": [
        "\n",
        "## Task 4: Predict Churn\n",
        "\n",
        "**üéØ Goal:** Use ML.PREDICT to generate churn predictions.  \n",
        "**üìå Requirements:** Apply model to same input table.\n",
        "\n",
        "---\n",
        "\n",
        "### üß† Prompt Template  \n",
        "> Generate SQL to use ML.PREDICT on churn_model and return predictions by user_id.\n",
        "\n",
        "---\n",
        "\n",
        "### üë©‚Äçüè´ Example Prompt  \n",
        "> Predict churn using churn_model. Include user_id, predicted_churn_label, and prediction probability.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ Expected SQL Output\n",
        "```sql\n",
        "SELECT user_id, predicted_churn_label, predicted_churn_label_probs\n",
        "FROM ML.PREDICT(MODEL `your_dataset.churn_model`,\n",
        "      (SELECT * FROM `your_dataset.churn_features`));\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### üîç Checkpoint  \n",
        "Inspect top churn risk users. Validate probabilities.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "# Construct a BigQuery client object.\n",
        "client = bigquery.Client()\n",
        "\n",
        "query_predict_churn = \"\"\"\n",
        "SELECT\n",
        "    user_id,\n",
        "    predicted_churn_label,\n",
        "    predicted_churn_label_probs\n",
        "FROM\n",
        "    ML.PREDICT(MODEL `mgmt-467.netflix.churn_model`,\n",
        "        (SELECT\n",
        "            user_id,\n",
        "            region,\n",
        "            plan_tier,\n",
        "            age_band,\n",
        "            avg_rating,\n",
        "            total_minutes\n",
        "        FROM\n",
        "            `mgmt-467.netflix.cleaned_features`)); -- Changed input table to cleaned_features\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    query_job = client.query(query_predict_churn)  # Make an API request.\n",
        "    print(f\"Job {query_job.job_id} started to predict churn.\")\n",
        "    results = query_job.result()  # Wait for the job to complete.\n",
        "\n",
        "    print(\"Churn Prediction Results (Top 5):\")\n",
        "    for i, row in enumerate(results):\n",
        "        if i >= 5: # Display only top 5 for brevity\n",
        "            break\n",
        "        print(f\"  User ID: {row.user_id}, Predicted Churn: {row.predicted_churn_label}, Probability: {row.predicted_churn_label_probs}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error predicting churn using model `mgmt-467.netflix.churn_model`: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K54aMb2OqoPT",
        "outputId": "fb1a49df-1e77-4da2-88c4-26808c6b7058"
      },
      "id": "K54aMb2OqoPT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Job c28d358a-df85-43df-a77a-2c9f542df537 started to predict churn.\n",
            "Churn Prediction Results (Top 5):\n",
            "  User ID: user_00008, Predicted Churn: 0, Probability: [{'label': 1, 'prob': 0.15123665873560657}, {'label': 0, 'prob': 0.8487633412643935}]\n",
            "  User ID: user_00008, Predicted Churn: 0, Probability: [{'label': 1, 'prob': 0.15123665873560657}, {'label': 0, 'prob': 0.8487633412643935}]\n",
            "  User ID: user_00009, Predicted Churn: 0, Probability: [{'label': 1, 'prob': 0.15192225799575576}, {'label': 0, 'prob': 0.8480777420042442}]\n",
            "  User ID: user_00009, Predicted Churn: 0, Probability: [{'label': 1, 'prob': 0.15192225799575576}, {'label': 0, 'prob': 0.8480777420042442}]\n",
            "  User ID: user_00012, Predicted Churn: 0, Probability: [{'label': 1, 'prob': 0.14792381486266493}, {'label': 0, 'prob': 0.8520761851373351}]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}